{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard 활용\n",
    "\n",
    "\n",
    "\n",
    "## `Scalar`, `Histogram`, `Distribution`\n",
    "\n",
    "- Tensorboard `Scalars`, `Histogram`, `Distribution` 탭 사용\n",
    "- 텐서보드를 위한 summary data 를 파일에 기록, 확인\n",
    "- 텐서보드를 위한 histogram data 를 파일에 기록, 확인\n",
    "\n",
    "## 주요 메소드/단계\n",
    "\n",
    "- tf.summary.FileWriter(dir_path,graph)\n",
    "- tf.summary.scalar(a_tensor)\n",
    "- tf.summary.histogram(a_tensor)\n",
    "- tf.summary.merge([summary_1,summary_2,...])\n",
    "- tf.summary.merge_all()\n",
    "- summary_op eval\n",
    "- writer.add_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수요일 실습의 mnist_linear.py 에서 발췌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mnist_data import load_mnist, load_mnist_t10k\n",
    "from image_util import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1주차 수요일 MNIST 실습 데이터와 동일한 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mnist'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './mnist'\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다운로드 - 쉘 스크립트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if test ! -s ./mnist/t10k-images-idx3-ubyte\n",
    "then\n",
    "    mkdir -p ./mnist\n",
    "    cd ./mnist\n",
    "    echo \"$(pwd)\"\n",
    "    wget -q http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "    wget -q http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "    wget -q http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "    wget -q http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "    gzip -d *.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 특성 및, batch size, learning rate 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size    = 128\n",
    "learning_rate = 0.05\n",
    "\n",
    "input_size    = 28 * 28\n",
    "output_size   = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 훈련용 그래프 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_       = tf.placeholder(shape=[None, input_size],\n",
    "                        dtype=tf.float32, name=\"input\")\n",
    "label_       = tf.placeholder(shape=[None],\n",
    "                        dtype=tf.int64, name=\"label\")\n",
    "\n",
    "weights      = tf.Variable(tf.zeros([input_size, output_size]))\n",
    "biases       = tf.Variable(tf.zeros([output_size]))\n",
    "output       = tf.matmul(input_, weights) + biases\n",
    "pred         = tf.nn.softmax(output)\n",
    "\n",
    "label_onehot = tf.one_hot(label_, output_size, axis=1)\n",
    "loss         = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits=output,\n",
    "                        labels=label_onehot))\n",
    "trainer      = tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=learning_rate)\n",
    "optimize     = trainer.minimize(loss)\n",
    "\n",
    "correct      = tf.equal(tf.argmax(pred, axis=1), label_)\n",
    "accuracy     = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary_op 텐서를 그래프에 추가\n",
    "\n",
    "- `summary_op` 도 또 다른 `tensor` 라는 점에 유의\n",
    "- 따라서 `session.run()` 이나 `eval()` 없이 직접 사용할 수 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('loss',loss)\n",
    "tf.summary.scalar('accuracy',accuracy)\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프는 준비되었고, 이제 훈련/테스트를 위한 루프를 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels       = load_mnist(data_dir)\n",
    "t_images, t_labels   = load_mnist_t10k(data_dir)\n",
    "images               = images / 127.0 - 1.0\n",
    "t_images             = t_images / 127.0 - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세션 설정, 세션 생성, 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow_growth 옵션을 사용하면, 텐서플로우가\n",
    "# 시작할 때 무조건 GPU 메모리 전체를 할당해서\n",
    "# 쓰지 않고 필요한 만큼만 할당 받아 사용하도록\n",
    "# 할 수 있음\n",
    "config    = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "session   = tf.InteractiveSession(config=config)\n",
    "\n",
    "init      = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련용 배치 갯수, 테스트용 배치 갯수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_count     = 60000 // batch_size\n",
    "test_count      = 10000 // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary 를 logdir 디렉토리에 저장해 주는 FileWriter 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir/events.out.tfevents.1504687195.rhee-mbp.local\r\n",
      "logdir\r\n"
     ]
    }
   ],
   "source": [
    "# 혹시 이전 실행에서 만든 결과가 파일로 저장되어 있으면 먼저 지우고 시작\n",
    "!rm -fvr logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x117f19d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter('logdir',graph=tf.get_default_graph())\n",
    "writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary 를 기록할 때 사용할 스텝 카운터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련을 위한 루프는 화요일 실습의 mnist_linear.py 에서 발췌\n",
    "\n",
    "- line 9,10 과 23,24 에 추가된 writer 사용방법에 주목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss: 0.51362 acc: 0.85306 test_acc: 89.49%\n",
      "epoch 2: loss: 0.34259 acc: 0.90014 test_acc: 90.27%\n",
      "epoch 3: loss: 0.32064 acc: 0.90680 test_acc: 90.61%\n",
      "epoch 4: loss: 0.30919 acc: 0.91017 test_acc: 90.84%\n",
      "epoch 5: loss: 0.30176 acc: 0.91279 test_acc: 90.94%\n",
      "epoch 6: loss: 0.29638 acc: 0.91485 test_acc: 90.95%\n",
      "epoch 7: loss: 0.29221 acc: 0.91642 test_acc: 90.96%\n",
      "epoch 8: loss: 0.28883 acc: 0.91779 test_acc: 91.08%\n",
      "epoch 9: loss: 0.28601 acc: 0.91887 test_acc: 91.13%\n",
      "epoch 10: loss: 0.28359 acc: 0.91989 test_acc: 91.18%\n",
      "epoch 11: loss: 0.28148 acc: 0.92054 test_acc: 91.18%\n",
      "epoch 12: loss: 0.27962 acc: 0.92111 test_acc: 91.25%\n",
      "epoch 13: loss: 0.27795 acc: 0.92159 test_acc: 91.34%\n",
      "epoch 14: loss: 0.27644 acc: 0.92211 test_acc: 91.35%\n",
      "epoch 15: loss: 0.27507 acc: 0.92248 test_acc: 91.42%\n",
      "epoch 16: loss: 0.27381 acc: 0.92286 test_acc: 91.44%\n",
      "epoch 17: loss: 0.27265 acc: 0.92321 test_acc: 91.43%\n",
      "epoch 18: loss: 0.27158 acc: 0.92351 test_acc: 91.43%\n",
      "epoch 19: loss: 0.27058 acc: 0.92386 test_acc: 91.45%\n",
      "epoch 20: loss: 0.26964 acc: 0.92420 test_acc: 91.42%\n",
      "epoch 21: loss: 0.26876 acc: 0.92441 test_acc: 91.47%\n",
      "epoch 22: loss: 0.26794 acc: 0.92475 test_acc: 91.47%\n",
      "epoch 23: loss: 0.26716 acc: 0.92495 test_acc: 91.44%\n",
      "epoch 24: loss: 0.26642 acc: 0.92518 test_acc: 91.45%\n",
      "epoch 25: loss: 0.26572 acc: 0.92560 test_acc: 91.46%\n",
      "epoch 26: loss: 0.26505 acc: 0.92585 test_acc: 91.48%\n",
      "epoch 27: loss: 0.26442 acc: 0.92613 test_acc: 91.50%\n",
      "epoch 28: loss: 0.26381 acc: 0.92627 test_acc: 91.53%\n",
      "epoch 29: loss: 0.26323 acc: 0.92640 test_acc: 91.55%\n",
      "epoch 30: loss: 0.26268 acc: 0.92662 test_acc: 91.57%\n",
      "epoch 31: loss: 0.26214 acc: 0.92672 test_acc: 91.60%\n",
      "epoch 32: loss: 0.26163 acc: 0.92690 test_acc: 91.60%\n",
      "epoch 33: loss: 0.26114 acc: 0.92708 test_acc: 91.61%\n",
      "epoch 34: loss: 0.26067 acc: 0.92720 test_acc: 91.62%\n",
      "epoch 35: loss: 0.26021 acc: 0.92732 test_acc: 91.61%\n",
      "epoch 36: loss: 0.25977 acc: 0.92742 test_acc: 91.63%\n",
      "epoch 37: loss: 0.25935 acc: 0.92760 test_acc: 91.59%\n",
      "epoch 38: loss: 0.25893 acc: 0.92777 test_acc: 91.61%\n",
      "epoch 39: loss: 0.25854 acc: 0.92783 test_acc: 91.61%\n",
      "epoch 40: loss: 0.25815 acc: 0.92793 test_acc: 91.63%\n",
      "epoch 41: loss: 0.25778 acc: 0.92815 test_acc: 91.66%\n",
      "epoch 42: loss: 0.25741 acc: 0.92825 test_acc: 91.69%\n",
      "epoch 43: loss: 0.25706 acc: 0.92834 test_acc: 91.70%\n",
      "epoch 44: loss: 0.25672 acc: 0.92844 test_acc: 91.71%\n",
      "epoch 45: loss: 0.25639 acc: 0.92850 test_acc: 91.70%\n",
      "epoch 46: loss: 0.25606 acc: 0.92860 test_acc: 91.71%\n",
      "epoch 47: loss: 0.25575 acc: 0.92879 test_acc: 91.71%\n",
      "epoch 48: loss: 0.25544 acc: 0.92877 test_acc: 91.71%\n",
      "epoch 49: loss: 0.25514 acc: 0.92897 test_acc: 91.72%\n",
      "epoch 50: loss: 0.25485 acc: 0.92902 test_acc: 91.73%\n"
     ]
    }
   ],
   "source": [
    "for ep in range(50):\n",
    "    total_loss = 0\n",
    "    total_acc_v = 0\n",
    "    for i in range(batch_count):\n",
    "        img = np.reshape(\n",
    "                images[i*batch_size:(i+1)*batch_size],\n",
    "                [batch_size, 28 * 28])\n",
    "        lbl = (labels[i*batch_size:(i+1)*batch_size])\n",
    "        _, loss_v, acc_v, summary_v = session.run([\n",
    "                                        optimize, loss, accuracy, summary_op], \\\n",
    "                                        feed_dict= {input_: img, label_: lbl})\n",
    "        \n",
    "        writer.add_summary(summary_v)   # <<<===== add_summary!\n",
    "        step += 1\n",
    "        \n",
    "        total_loss += loss_v\n",
    "        total_acc_v += acc_v\n",
    "\n",
    "    total_acc = 0\n",
    "    for a in range(test_count):\n",
    "        index = a * batch_size\n",
    "        img = np.reshape(\n",
    "                t_images[index:index+batch_size], \\\n",
    "                [batch_size, 28 * 28])\n",
    "        lbl = t_labels[index:index+batch_size]\n",
    "        acc,summary_t = session.run(\n",
    "                            [accuracy, summary_op], \\\n",
    "                            feed_dict={input_:img, label_:lbl})\n",
    "        \n",
    "        writer.add_summary(summary_v)   # <<<===== add_summary!\n",
    "        step += 1\n",
    "\n",
    "        total_acc += acc\n",
    "\n",
    "    total_acc = total_acc / test_count\n",
    "\n",
    "    print('epoch %d: loss: %.5f acc: %.5f test_acc: %.2f%%' % (\n",
    "        ep+1, \n",
    "        total_loss / batch_count, \n",
    "        total_acc_v / batch_count, \n",
    "        total_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서보드 실행\n",
    "\n",
    "- `SCALARS` 탭에서 그래프 확인\n",
    "- `Horizontal Axis` 의 선택을 `STEP`, `RELATIVE`, `WALL` 로 전환 해 봄\n",
    "- `Smoothing` 슬라이더를 움직여 봄\n",
    "- `Ignore outliers` 체크박스의 효과를 확인\n",
    "- `Show data download links` 및, 다운로드된 csv 파일을 다른 프로그램으로 확인\n",
    "- filter 기능 확인\n",
    "- 텐서보드 감상 후 정지 버튼을 누르거나 `Kernel` `->` `Interrupt` 메뉴를 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard 54 at http://rhee-mbp.local:6006\n",
      "(Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기대했던 그림이 나오지 않았을 것입니다\n",
    "\n",
    "- add_summary() 호출시 global_step= 값을 적어 줘야 함\n",
    "\n",
    "- 이번에는 [tqdm](https://pypi.python.org/pypi/tqdm) 을 써 봅시다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/envs/tensorflow/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "# 먼저, 현재 env 에 tqdm 이 설치되어 있지 않으면 설치\n",
    "# 쉘 명령어 pip 를 이용\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: loss: 0.24566 acc: 0.93187 test_acc: 91.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in tqdm(range(50)):\n",
    "    total_loss = 0\n",
    "    total_acc_v = 0\n",
    "    for i in range(batch_count):\n",
    "        img = np.reshape(images[i*batch_size:(i+1)*batch_size], \\\n",
    "                         [batch_size, 28 * 28])\n",
    "        lbl = (labels[i*batch_size:(i+1)*batch_size])\n",
    "        _, loss_v, acc_v, summary_v = session.run([ \\\n",
    "                                        optimize, loss, accuracy, summary_op], \\\n",
    "                                        feed_dict= {input_: img, label_: lbl})\n",
    "\n",
    "        writer.add_summary(summary_v,step)\n",
    "        step += 1\n",
    "        \n",
    "        total_loss += loss_v\n",
    "        total_acc_v += acc_v\n",
    "\n",
    "    total_acc = 0\n",
    "    for a in range(test_count):\n",
    "        index = a * batch_size\n",
    "        img = np.reshape(t_images[index:index+batch_size], \\\n",
    "                         [batch_size, 28 * 28])\n",
    "        lbl = t_labels[index:index+batch_size]\n",
    "        acc,summary_t = session.run([accuracy, summary_op], \\\n",
    "                                    feed_dict={input_:img, label_:lbl})\n",
    "        \n",
    "        writer.add_summary(summary_v,step)\n",
    "        step += 1\n",
    "\n",
    "        total_acc += acc\n",
    "    total_acc = total_acc / test_count\n",
    "\n",
    "print('epoch %d: loss: %.5f acc: %.5f test_acc: %.2f%%' % (\n",
    "    ep+1, \n",
    "    total_loss / batch_count, \n",
    "    total_acc_v / batch_count, \n",
    "    total_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard 54 at http://rhee-mbp.local:6006\n",
      "(Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logdir 에 뭐가 들어있는지 잠깐확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6368\r\n",
      "drwxr-xr-x   3 rhee  staff      102 Sep  6 18:05 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxrwxr-x  37 rhee  staff     1258 Sep  6 18:08 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 rhee  staff  3248369 Sep  6 18:06 events.out.tfevents.1504688727.rhee-mbp.local\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram 기능 활용\n",
    "\n",
    "- 특정 데이터의 히스토그램을 만들어 볼 수 있는 기능\n",
    "\n",
    "- 활용 예:\n",
    "    - 훈련용 데이터에 편향성이 있는지 테스트\n",
    "\n",
    "    - `label_` placeholder 에 들어왔던 값들의 histogram 시각화\n",
    "\n",
    "        `label_ = tf.placeholder(shape=[None], dtype=tf.int64, name=\"label\")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logdir2 에 저장하기로\n",
    "!rm -fr logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer 는 새로운 logdir2 에 대해서 새로 만들어 사용\n",
    "writer = tf.summary.FileWriter('logdir2',graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 먼저, 그래프에 histogram summary 를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_labels    = tf.summary.histogram('labels',tf.cast(label_,tf.float32))\n",
    "hist_outputs   = tf.summary.histogram('outputs',tf.argmax(output,axis=1))\n",
    "\n",
    "# summary_op 를 재정의. tf.summary.merge() 를 이용\n",
    "summary_op = tf.summary.merge([hist_labels, hist_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나머지는 이전과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이건 텐서보드 히스토그램을 위한 변수가 아님. 용도는 끝에서 설명\n",
    "label_stats = [0] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:37<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: loss: 0.24095 acc: 0.93339 test_acc: 91.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in tqdm(range(50)):\n",
    "    total_loss = 0\n",
    "    total_acc_v = 0\n",
    "    for i in range(batch_count):\n",
    "        img = np.reshape(images[i*batch_size:(i+1)*batch_size],\n",
    "                         [batch_size, 28 * 28])\n",
    "        lbl = (labels[i*batch_size:(i+1)*batch_size])\n",
    "        \n",
    "        for l in lbl: \n",
    "            label_stats[l] += 1\n",
    "            \n",
    "        _, loss_v, acc_v, summary_v = session.run(\n",
    "                                        [optimize, loss, accuracy, summary_op],\n",
    "                                        feed_dict= {input_: img, label_: lbl})\n",
    "        \n",
    "        writer.add_summary(summary_v,step)\n",
    "        step += 1\n",
    "\n",
    "        total_loss += loss_v\n",
    "        total_acc_v += acc_v\n",
    "\n",
    "    total_acc = 0\n",
    "    for a in range(test_count):\n",
    "        index = a * batch_size\n",
    "        img = np.reshape(t_images[index:index+batch_size],\n",
    "                         [batch_size, 28 * 28])\n",
    "        lbl = t_labels[index:index+batch_size]\n",
    "        \n",
    "        for l in lbl:\n",
    "            label_stats[l] += 1\n",
    "\n",
    "        acc,summary_t = session.run([accuracy, summary_op],\n",
    "                                    feed_dict={input_:img, label_:lbl})\n",
    "        \n",
    "        writer.add_summary(summary_v,step)\n",
    "        step += 1\n",
    "        \n",
    "        total_acc += acc\n",
    "    total_acc = total_acc / test_count\n",
    "    \n",
    "print('epoch %d: loss: %.5f acc: %.5f test_acc: %.2f%%' % (\n",
    "    ep+1, \n",
    "    total_loss / batch_count, \n",
    "    total_acc_v / batch_count, \n",
    "    total_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard 54 at http://rhee-mbp.local:6006\n",
      "(Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logdir2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림이 좀 이상할 수 있음, 다른 방법으로 다시 확인\n",
    "\n",
    "- 위에 이렇게 적은 부분이 있습니다\n",
    "\n",
    "        # 이건 텐서보드 히스토그램을 위한 변수가 아님. 용도는 끝에서 설명\n",
    "        label_stats = [0] * 10\n",
    "\n",
    "- 학습 및 테스트 루프의 중간에 이런 코드도 있습니다\n",
    "\n",
    "        for l in lbl:\n",
    "            label_stats[l] += 1\n",
    "\n",
    "- 이렇게 파이썬 코드로 수집한 히스토그램 데이터를 그래프로 그려 봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRqSpM4MDUlSZ/8PMgjQtoN+u/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11814ddd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pyplot 로 그린 그래프가 jupyter notebook 셀 내부에\n",
    "# 그려지게 하려면 %matplotlib inline 이라고 적어줍니다.\n",
    "# (이건 jupyter notebook 에서만 가능함. 파이썬에서 지원하는 것이 아님)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(label_stats)),label_stats);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서보드는 다양한 범위의 데이터에 대한 히스토그램을 보여주기 위해서 몇 가지 트릭을 사용함\n",
    "\n",
    "- [exponentially distributed bins](https://www.tensorflow.org/get_started/tensorboard_histograms)\n",
    "\n",
    "    - 0 에 가까울 수록 많은 갯수의 bin 할당 ( 보다 정확하게 구분되어 보임 )\n",
    "    \n",
    "    - 값이 클수록 적은 갯수의 bin 할당, 따라서 많은 값들이 동일한 bins 에 포함되어 값이 뭉쳐져서 보임\n",
    "    \n",
    "    - 실제로 입력한 값들이 정수라고 해도, 히스토그램 상에서는 bin 중심과 bin 너비가 실수로 표현되고, 카운터도 실수로 표현됨\n",
    "\n",
    "\n",
    "- [reservoir sampling](https://en.wikipedia.org/wiki/Reservoir_sampling)\n",
    "\n",
    "    - \"Reservoir sampling is a family of randomized algorithms for randomly choosing a sample of k items from a list S containing n items, where n is either a very large or unknown number. Typically n is large enough that the list doesn't fit into main memory.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
